{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
      ],
      "metadata": {
        "id": "ciPLHW5CQn3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "torch.cuda.ipc_collect()\n"
      ],
      "metadata": {
        "id": "hkhIX5vSQt0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNM8goZ8vh73"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/yandex-research/tabm/blob/main/example.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "# TabM\n",
        "\n",
        "This notebook provides a usage example of the `tabm` package from the\n",
        "[TabM](https://github.com/yandex-research/tabm) project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsRLOsCIvh76",
        "outputId": "87c87b57-5c6e-4931-df30-daa0c980564e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rtdl_num_embeddings in /usr/local/lib/python3.11/dist-packages (0.0.12)\n",
            "Requirement already satisfied: torch<3,>=1.12 in /usr/local/lib/python3.11/dist-packages (from rtdl_num_embeddings) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->rtdl_num_embeddings) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=1.12->rtdl_num_embeddings) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=1.12->rtdl_num_embeddings) (3.0.2)\n",
            "Requirement already satisfied: tabm in /usr/local/lib/python3.11/dist-packages (0.0.1)\n",
            "Requirement already satisfied: torch<3,>=1.12 in /usr/local/lib/python3.11/dist-packages (from tabm) (2.6.0+cu124)\n",
            "Requirement already satisfied: rtdl_num_embeddings<0.1,>=0.0.12 in /usr/local/lib/python3.11/dist-packages (from tabm) (0.0.12)\n",
            "Requirement already satisfied: typing_extensions<5,>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from tabm) (4.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=1.12->tabm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=1.12->tabm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=1.12->tabm) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install rtdl_num_embeddings\n",
        "!pip install tabm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XA3mG4Eevh78"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "from copy import deepcopy\n",
        "from typing import Any, Literal, NamedTuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import rtdl_num_embeddings  # https://github.com/yandex-research/rtdl-num-embeddings\n",
        "import scipy.special\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import sklearn.preprocessing\n",
        "import tabm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim\n",
        "from torch import Tensor\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDqhPxI9vh79"
      },
      "outputs": [],
      "source": [
        "seed = 0\n",
        "random.seed(seed)\n",
        "np.random.seed(seed + 1)\n",
        "torch.manual_seed(seed + 2)\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4LRByuSvh79"
      },
      "source": [
        "# Dataset example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5ooMrk4vh79",
        "outputId": "29a49597-35b9-4841-ecf5-2d888cb380b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train    x_num    (13209, 8)    float32\n",
            "train    y        (13209,)      float32\n",
            "val      x_num    (3303, 8)     float32\n",
            "val      y        (3303,)       float32\n",
            "test     x_num    (4128, 8)     float32\n",
            "test     y        (4128,)       float32\n"
          ]
        }
      ],
      "source": [
        "# >>> Dataset.\n",
        "TaskType = Literal['regression', 'binclass', 'multiclass']\n",
        "\n",
        "# Regression.\n",
        "task_type: TaskType = 'regression'\n",
        "n_classes = None\n",
        "dataset = sklearn.datasets.fetch_california_housing()\n",
        "X_num: np.ndarray = dataset['data']\n",
        "Y: np.ndarray = dataset['target']\n",
        "\n",
        "# Classification.\n",
        "# n_classes = 2\n",
        "# assert n_classes >= 2\n",
        "# task_type: TaskType = 'binclass' if n_classes == 2 else 'multiclass'\n",
        "# X_num, Y = sklearn.datasets.make_classification(\n",
        "#     n_samples=20000,\n",
        "#     n_features=8,\n",
        "#     n_classes=n_classes,\n",
        "#     n_informative=3,\n",
        "#     n_redundant=2,\n",
        "# )\n",
        "\n",
        "task_is_regression = task_type == 'regression'\n",
        "\n",
        "# >>> Numerical (continuous) features.\n",
        "X_num: np.ndarray = X_num.astype(np.float32)\n",
        "n_num_features = X_num.shape[1]\n",
        "\n",
        "# >>> Categorical features.\n",
        "# NOTE: the above datasets do not have categorical features, however,\n",
        "# for the demonstration purposes, it is possible to generate them.\n",
        "cat_cardinalities = [\n",
        "    # NOTE: uncomment the two lines below to add two categorical features.\n",
        "    # 4,  # Allowed values: [0, 1, 2, 3].\n",
        "    # 7,  # Allowed values: [0, 1, 2, 3, 4, 5, 6].\n",
        "]\n",
        "X_cat = (\n",
        "    np.column_stack([np.random.randint(0, c, (len(X_num),)) for c in cat_cardinalities])\n",
        "    if cat_cardinalities\n",
        "    else None\n",
        ")\n",
        "\n",
        "# >>> Labels.\n",
        "if task_type == 'regression':\n",
        "    Y = Y.astype(np.float32)\n",
        "else:\n",
        "    assert n_classes is not None\n",
        "    Y = Y.astype(np.int64)\n",
        "    assert set(Y.tolist()) == set(range(n_classes)), (\n",
        "        'Classification labels must form the range [0, 1, ..., n_classes - 1]'\n",
        "    )\n",
        "\n",
        "# >>> Split the dataset.\n",
        "all_idx = np.arange(len(Y))\n",
        "trainval_idx, test_idx = sklearn.model_selection.train_test_split(\n",
        "    all_idx, train_size=0.8\n",
        ")\n",
        "train_idx, val_idx = sklearn.model_selection.train_test_split(\n",
        "    trainval_idx, train_size=0.8\n",
        ")\n",
        "data_numpy = {\n",
        "    'train': {'x_num': X_num[train_idx], 'y': Y[train_idx]},\n",
        "    'val': {'x_num': X_num[val_idx], 'y': Y[val_idx]},\n",
        "    'test': {'x_num': X_num[test_idx], 'y': Y[test_idx]},\n",
        "}\n",
        "if X_cat is not None:\n",
        "    data_numpy['train']['x_cat'] = X_cat[train_idx]\n",
        "    data_numpy['val']['x_cat'] = X_cat[val_idx]\n",
        "    data_numpy['test']['x_cat'] = X_cat[test_idx]\n",
        "\n",
        "for part, part_data in data_numpy.items():\n",
        "    for key, value in part_data.items():\n",
        "        print(f'{part:<5}    {key:<5}    {value.shape!r:<10}    {value.dtype}')\n",
        "        del key, value\n",
        "    del part, part_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tasks"
      ],
      "metadata": {
        "id": "g-AM3YKHNEkZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "AAYCRLM802mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Abalone"
      ],
      "metadata": {
        "id": "V33T4jG-0qZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "abalone= pd.read_csv(\"abalone.csv\")\n",
        "\n",
        "# Data (as pandas DataFrames)\n",
        "X = abalone.iloc[:,:-1]\n",
        "y = abalone[\"Rings\"]\n",
        "\n",
        "# Because RMSLE score, we make a conversion like below:\n",
        "y_log = y #np.log(1 + y)\n",
        "y_train=y_log.iloc[:2784]\n",
        "y_test=y_log.iloc[2784:]\n",
        "\n",
        "# Add the end for getting the result back to original like below:\n",
        "# y = np.exp(y_log) - 1\n",
        "\n",
        "# Dummy data for train and test (for demonstration)\n",
        "train = pd.DataFrame(X.iloc[:2784,:], columns=X.columns)\n",
        "train['Sex'] = np.random.choice(['M', 'F', 'I'], size=len(train))\n",
        "\n",
        "test = pd.DataFrame(X.iloc[2784:,:], columns=X.columns)\n",
        "test['Sex'] = np.random.choice(['M', 'F', 'I'], size=len(test))\n",
        "\n",
        "# OneHotEncoding the 'Sex' column for both train and test datasets\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "\n",
        "train_encoded = pd.concat([\n",
        "                    train.iloc[:, 1:].reset_index(drop=True),  # Exclude the original 'Sex' column\n",
        "                    pd.DataFrame(encoder.fit_transform(train[['Sex']]).astype('int'),\n",
        "                                 columns=encoder.categories_[0])\n",
        "                    ],\n",
        "                    axis=1\n",
        "                )\n",
        "\n",
        "test_encoded = pd.concat([\n",
        "                    test.iloc[:, 1:].reset_index(drop=True),  # Exclude the original 'Sex' column\n",
        "                    pd.DataFrame(encoder.transform(test[['Sex']]).astype('int'),\n",
        "                                 columns=encoder.categories_[0]) ],\n",
        "                    axis=1\n",
        "                )\n",
        "\n",
        "# Now, 'train_encoded' and 'test_encoded' contain the encoded 'Sex' column.\n",
        "\n",
        "def log_transformation(data, columns):\n",
        "    for column in columns:\n",
        "        positive_values = data[column] - data[column].min() + 1\n",
        "        data[f'{column}_log'] = np.log(positive_values)\n",
        "    return data\n",
        "\n",
        "\n",
        "if False:\n",
        "    train = log_transformation(train_encoded, ['Length', 'Diameter', 'Height', 'Whole_weight', 'Shucked_weight','Viscera_weight', 'Shell_weight'])\n",
        "    test  = log_transformation(test_encoded, ['Length', 'Diameter', 'Height', 'Whole_weight', 'Shucked_weight','Viscera_weight', 'Shell_weight'])"
      ],
      "metadata": {
        "id": "nLgqzGAC0tOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_x, test_y=np.asarray(test_encoded),np.asarray(y_test)\n",
        "train_x, train_y = np.asarray(train_encoded),np.asarray(y_train)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1)) #StandardScaler()\n",
        "traindata = scaler.fit_transform(train_x)\n",
        "\n",
        "scaler_y = MinMaxScaler(feature_range=(0, 1)) #StandardScaler()\n",
        "trainlabel= scaler_y.fit_transform(train_y.reshape(-1,1))\n",
        "testlabel= scaler_y.transform(test_y.reshape(-1,1))\n",
        "\n",
        "testdata = scaler.transform(test_x)\n",
        "test_x, test_y=np.asarray(testdata),np.asarray(testlabel)\n",
        "train_x, train_y = np.asarray(traindata),np.asarray(trainlabel)"
      ],
      "metadata": {
        "id": "8eZmyLZh1scU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "oNxgyI0H2J4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_numpy = {\n",
        "    'train': {'x_num': train_x.astype(np.float32), 'y': train_y.astype(np.float32)},\n",
        "    'val': {'x_num': val_x.astype(np.float32), 'y': val_y.astype(np.float32)},\n",
        "    'test': {'x_num': test_x.astype(np.float32), 'y': test_y.astype(np.float32)},\n",
        "}"
      ],
      "metadata": {
        "id": "gst-T5Et1YPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zoxiw3YHQflN",
        "outputId": "ed1bfa42-c29d-4fe0-9200-db140179298a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.3149676956209619)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## housing"
      ],
      "metadata": {
        "id": "MzFXgBorTXTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import boston_housing\n",
        "(traindata_o,trainlabel_o ), (testdata_o, testlabel_o)  =boston_housing.load_data()\n",
        "testdata_o= np.concatenate([testdata_o,traindata_o[337:]],axis=0)\n",
        "testlabel_o= np.concatenate([testlabel_o,trainlabel_o[337:]],axis=0)\n",
        "traindata_o=traindata_o[:337]\n",
        "trainlabel_o=trainlabel_o[:337]\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "traindata = scaler.fit_transform(traindata_o)\n",
        "\n",
        "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
        "trainlabel= scaler_y.fit_transform(trainlabel_o.reshape(-1,1))\n",
        "testlabel= scaler_y.transform(testlabel_o.reshape(-1,1))\n",
        "testdata = scaler.transform(testdata_o)\n",
        "test_x, test_y=np.asarray(testdata),np.asarray(testlabel)\n",
        "train_x, train_y = np.asarray(traindata),np.asarray(trainlabel)"
      ],
      "metadata": {
        "id": "0sUc-_kSTYmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "7Qvnm5-iTdz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_numpy = {\n",
        "    'train': {'x_num': train_x.astype(np.float32), 'y': train_y.astype(np.float32)},\n",
        "    'val': {'x_num': val_x.astype(np.float32), 'y': val_y.astype(np.float32)},\n",
        "    'test': {'x_num': test_x.astype(np.float32), 'y': test_y.astype(np.float32)},\n",
        "}"
      ],
      "metadata": {
        "id": "vwzN3rpcTbLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYJjypnSTgZe",
        "outputId": "5aee9791-dbc9-4060-992a-0e4a893fd921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.4086522024983563)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IZMIR"
      ],
      "metadata": {
        "id": "x8tJrgi31etV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(\"izmir_df.csv\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "IHMxTniZ4L6t",
        "outputId": "d59dd1e4-a687-45eb-8e5a-0638838ab9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Max_temperature  Min_temperature  Dewpoint  Precipitation  \\\n",
              "0             88.2             57.2      53.6            0.0   \n",
              "1             88.0             58.6      54.9            0.0   \n",
              "2             91.6             62.1      60.4            0.0   \n",
              "3             64.4             42.8      37.4            0.2   \n",
              "4             94.1             72.3      46.8            0.0   \n",
              "\n",
              "   Sea_level_pressure  Standard_pressure  Visibility  Wind_speed  \\\n",
              "0               29.96                7.3        9.09        16.1   \n",
              "1               29.84                7.3       10.70        18.3   \n",
              "2               29.76                7.2        8.29        18.3   \n",
              "3               30.15                7.8       21.10        27.5   \n",
              "4               29.86                7.2       17.20        25.3   \n",
              "\n",
              "   Max_wind_speed  Mean_temperature  \n",
              "0           34.28              74.3  \n",
              "1           34.28              75.2  \n",
              "2           34.28              76.1  \n",
              "3           34.28              47.1  \n",
              "4           34.28              83.9  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-984c69ff-178b-4d1e-ad38-78138633d8f2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Max_temperature</th>\n",
              "      <th>Min_temperature</th>\n",
              "      <th>Dewpoint</th>\n",
              "      <th>Precipitation</th>\n",
              "      <th>Sea_level_pressure</th>\n",
              "      <th>Standard_pressure</th>\n",
              "      <th>Visibility</th>\n",
              "      <th>Wind_speed</th>\n",
              "      <th>Max_wind_speed</th>\n",
              "      <th>Mean_temperature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>88.2</td>\n",
              "      <td>57.2</td>\n",
              "      <td>53.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.96</td>\n",
              "      <td>7.3</td>\n",
              "      <td>9.09</td>\n",
              "      <td>16.1</td>\n",
              "      <td>34.28</td>\n",
              "      <td>74.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>88.0</td>\n",
              "      <td>58.6</td>\n",
              "      <td>54.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.84</td>\n",
              "      <td>7.3</td>\n",
              "      <td>10.70</td>\n",
              "      <td>18.3</td>\n",
              "      <td>34.28</td>\n",
              "      <td>75.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>91.6</td>\n",
              "      <td>62.1</td>\n",
              "      <td>60.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.76</td>\n",
              "      <td>7.2</td>\n",
              "      <td>8.29</td>\n",
              "      <td>18.3</td>\n",
              "      <td>34.28</td>\n",
              "      <td>76.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>64.4</td>\n",
              "      <td>42.8</td>\n",
              "      <td>37.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>30.15</td>\n",
              "      <td>7.8</td>\n",
              "      <td>21.10</td>\n",
              "      <td>27.5</td>\n",
              "      <td>34.28</td>\n",
              "      <td>47.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>94.1</td>\n",
              "      <td>72.3</td>\n",
              "      <td>46.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.86</td>\n",
              "      <td>7.2</td>\n",
              "      <td>17.20</td>\n",
              "      <td>25.3</td>\n",
              "      <td>34.28</td>\n",
              "      <td>83.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-984c69ff-178b-4d1e-ad38-78138633d8f2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-984c69ff-178b-4d1e-ad38-78138633d8f2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-984c69ff-178b-4d1e-ad38-78138633d8f2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dd6097b7-ee38-49d0-9e4f-b777cd6b0539\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dd6097b7-ee38-49d0-9e4f-b777cd6b0539')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dd6097b7-ee38-49d0-9e4f-b777cd6b0539 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1461,\n  \"fields\": [\n    {\n      \"column\": \"Max_temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.92671308817569,\n        \"min\": 36.7,\n        \"max\": 105.0,\n        \"num_unique_values\": 300,\n        \"samples\": [\n          69.1,\n          90.0,\n          44.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Min_temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.226079817410078,\n        \"min\": 15.8,\n        \"max\": 78.6,\n        \"num_unique_values\": 284,\n        \"samples\": [\n          59.9,\n          76.6,\n          37.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dewpoint\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.344544576958961,\n        \"min\": 13.6,\n        \"max\": 64.4,\n        \"num_unique_values\": 387,\n        \"samples\": [\n          41.7,\n          31.3,\n          36.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precipitation\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.35280080407851216,\n        \"min\": 0.0,\n        \"max\": 7.6,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          0.4,\n          4.2,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sea_level_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16768897272232958,\n        \"min\": 29.26,\n        \"max\": 30.48,\n        \"num_unique_values\": 90,\n        \"samples\": [\n          29.98,\n          29.66,\n          30.32\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Standard_pressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6849531931908546,\n        \"min\": 2.3,\n        \"max\": 10.1,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          4.5,\n          5.4,\n          4.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Visibility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.406664717899174,\n        \"min\": 0.92,\n        \"max\": 29.1,\n        \"num_unique_values\": 198,\n        \"samples\": [\n          7.14,\n          5.18,\n          10.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Wind_speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.135250472185029,\n        \"min\": 4.72,\n        \"max\": 68.8,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          36.9,\n          6.9,\n          11.39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Max_wind_speed\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.4418256139717394,\n        \"min\": 16.11,\n        \"max\": 55.24,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          34.28,\n          48.33,\n          18.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Mean_temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.376231946432897,\n        \"min\": 29.4,\n        \"max\": 89.9,\n        \"num_unique_values\": 489,\n        \"samples\": [\n          85.6,\n          66.4,\n          57.6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Supongamos que ya tienes el DataFrame cargado en 'df'\n",
        "# Definir tamaños específicos para train y test\n",
        "train_size = 974\n",
        "test_size = 487\n",
        "\n",
        "# Dividir los datos\n",
        "train_x, test_x,train_y,test_y = train_test_split(df.iloc[:,:-1],df.iloc[:,-1], train_size=train_size, test_size=test_size, random_state=42)\n",
        "train_x, test_x= train_x.values, test_x.values\n",
        "train_y,test_y= train_y.values.reshape(-1,1),test_y.values.reshape(-1,1)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1)) #StandardScaler() #StandardScaler(feature_range=(0, 1)) #StandardScaler()\n",
        "train_x = scaler.fit_transform(train_x)\n",
        "test_x = scaler.transform(test_x)\n",
        "\n",
        "scaler_y = MinMaxScaler(feature_range=(0, 1)) #StandardScaler()\n",
        "train_y= scaler_y.fit_transform(train_y)\n",
        "test_y= scaler_y.transform(test_y)\n",
        "\n",
        "print(train_x.shape, train_y.shape,test_x.shape, test_y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C7s7knK2C-N",
        "outputId": "87be02f1-8fdc-43c2-bf6b-7cc4dffff401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(974, 9) (974, 1) (487, 9) (487, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "CPDWvKEW4zvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_numpy = {\n",
        "    'train': {'x_num': train_x.astype(np.float32), 'y': train_y.astype(np.float32)},\n",
        "    'val': {'x_num': val_x.astype(np.float32), 'y': val_y.astype(np.float32)},\n",
        "    'test': {'x_num': test_x.astype(np.float32), 'y': test_y.astype(np.float32)},\n",
        "}"
      ],
      "metadata": {
        "id": "z2WQ5p9r43rn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST"
      ],
      "metadata": {
        "id": "YUTrk-Up6jpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' For Keras dataset_load()'''\n",
        "import tensorflow.keras as keras\n",
        "(traindata_o, trainlabel), (testdata_o, testlabel) = keras.datasets.mnist.load_data()\n",
        "traindata_o = traindata_o.reshape(traindata_o.shape[0], 28*28).astype('float64')/255\n",
        "trainlabel = keras.utils.to_categorical(trainlabel, 10)\n",
        "testdata_o = testdata_o.reshape(testdata_o.shape[0], 28*28).astype('float64')/255\n",
        "testlabel = keras.utils.to_categorical(testlabel, 10)\n",
        "print(traindata_o.shape, trainlabel.shape, testdata_o.shape, testlabel.shape )\n",
        "\n",
        "#scaler = StandardScaler()\n",
        "#traindata = scaler.fit_transform(traindata_o)\n",
        "#if task== \"regression\":\n",
        "#        scaler_y = StandardScaler()\n",
        "#        self.train_y= scaler_y.fit_transform(self.train_y)\n",
        "#        self.test_y= scaler_y.fit_transform(self.test_y)\n",
        "#inference process\n",
        "#testdata = scaler.transform(testdata_o)\n",
        "\n",
        "test_x, test_y=np.asarray(testdata_o),np.asarray(testlabel)\n",
        "train_x, train_y = np.asarray(traindata_o),np.asarray(trainlabel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuiQ064L6mpM",
        "outputId": "fb11fe6a-3ac6-43d3-df0b-ed15649bed9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784) (60000, 10) (10000, 784) (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y=np.argmax(train_y, axis=1)\n",
        "test_y= np.argmax(test_y, axis=1)"
      ],
      "metadata": {
        "id": "zG-PAvup81T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "yqjrUQsi6pXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coil100"
      ],
      "metadata": {
        "id": "VFhuhtzDIL6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=np.load(\"coil100.npy\", mmap_mode='r')/255\n",
        "print(X.shape)\n",
        "y=np.load(\"coil100_y.npy\", mmap_mode='r')\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0knKF6BbINi3",
        "outputId": "b6bda4b2-dced-4527-841c-003f3ffccba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7200, 32, 32)\n",
            "(7200,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=y-1\n",
        "np.max(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52CprkaUMR4j",
        "outputId": "62a6f42a-f587-4635-e61d-383f8d0d5383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.int64(99)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X= X.reshape(7200, 32*32)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "train_x, test_x,train_y,test_y = train_test_split(X,y, test_size=2200, train_size=5000, shuffle=True, random_state=42)"
      ],
      "metadata": {
        "id": "4hXhkd1jIUFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "f_nriJ_cIsle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Isolet"
      ],
      "metadata": {
        "id": "KjEmMam9ReKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.load('isolet_labels.npy')\n",
        "features = np.load('isolet_features.npy')\n",
        "labels=labels-1\n",
        "np.max(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STVPwgr4Rf2y",
        "outputId": "932df944-5b80-46de-cc1c-96c5b0f79428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.uint8(25)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, test_x,train_y,test_y = train_test_split(features,labels ,train_size=1092, random_state=42)\n"
      ],
      "metadata": {
        "id": "Lj84dIBHSFwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "bovFmmZYSGTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbPFAkfGvh7-"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_numpy = {\n",
        "    'train': {'x_num': train_x.astype(np.float32), 'y': train_y}, #.astype(np.float32)\n",
        "    'val': {'x_num': val_x.astype(np.float32), 'y': val_y},\n",
        "    'test': {'x_num': test_x.astype(np.float32), 'y': test_y},\n",
        "}"
      ],
      "metadata": {
        "id": "5qxIimL36q_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_type=\"classification\"\n",
        "n_classes = 26 #100 #10\n",
        "cat_cardinalities = []"
      ],
      "metadata": {
        "id": "wLh3VX-w6tkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task_type=\"regression\"\n",
        "n_classes = None\n",
        "cat_cardinalities = []"
      ],
      "metadata": {
        "id": "xHHTcsZiGpWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#without additional preprocessing\n",
        "Y_train = data_numpy['train']['y'].copy()\n",
        "regression_label_stats = None"
      ],
      "metadata": {
        "id": "1EF6Ae7LUq5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybuCDui6vh7-"
      },
      "outputs": [],
      "source": [
        "# Feature preprocessing.\n",
        "# NOTE\n",
        "# The choice between preprocessing strategies depends on a task and a model.\n",
        "\n",
        "# Simple preprocessing strategy.\n",
        "# preprocessing = sklearn.preprocessing.StandardScaler().fit(\n",
        "#     data_numpy['train']['x_num']\n",
        "# )\n",
        "\n",
        "# Advanced preprocessing strategy.\n",
        "# The noise is added to improve the output of QuantileTransformer in some cases.\n",
        "x_num_train_numpy = data_numpy['train']['x_num']\n",
        "noise = (\n",
        "    np.random.default_rng(0)\n",
        "    .normal(0.0, 1e-5, x_num_train_numpy.shape)\n",
        "    .astype(x_num_train_numpy.dtype)\n",
        ")\n",
        "preprocessing = sklearn.preprocessing.QuantileTransformer(\n",
        "    n_quantiles=max(min(x_num_train_numpy.shape[0] // 30, 1000), 10),\n",
        "    output_distribution='normal',\n",
        "    subsample=10**9,\n",
        ").fit(x_num_train_numpy + noise)\n",
        "del x_num_train_numpy\n",
        "\n",
        "# Apply the preprocessing.\n",
        "for part in data_numpy:\n",
        "    data_numpy[part]['x_num'] = preprocessing.transform(data_numpy[part]['x_num'])\n",
        "\n",
        "\n",
        "# Label preprocessing.\n",
        "class RegressionLabelStats(NamedTuple):\n",
        "    mean: float\n",
        "    std: float\n",
        "\n",
        "\n",
        "Y_train = data_numpy['train']['y'].copy()\n",
        "if task_type == 'regression':\n",
        "    # For regression tasks, it is highly recommended to standardize the training labels.\n",
        "    regression_label_stats = RegressionLabelStats(\n",
        "        Y_train.mean().item(), Y_train.std().item()\n",
        "    )\n",
        "    Y_train = (Y_train - regression_label_stats.mean) / regression_label_stats.std\n",
        "else:\n",
        "    regression_label_stats = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDiLmgO6vh7-"
      },
      "source": [
        "#  PyTorch settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqB5WFoWvh7_",
        "outputId": "136812ba-7e8b-4e85-b6ec-781458cf6b59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:        CUDA\n",
            "AMP:           False\n",
            "torch.compile: False\n"
          ]
        }
      ],
      "source": [
        "# Device\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Convert data to tensors\n",
        "data = {\n",
        "    part: {k: torch.as_tensor(v, device=device) for k, v in data_numpy[part].items()}\n",
        "    for part in data_numpy\n",
        "}\n",
        "Y_train = torch.as_tensor(Y_train, device=device)\n",
        "if task_type == 'regression':\n",
        "    for part in data:\n",
        "        data[part]['y'] = data[part]['y'].float()\n",
        "    Y_train = Y_train.float()\n",
        "\n",
        "# Automatic mixed precision (AMP)\n",
        "# torch.float16 is implemented for completeness,\n",
        "# but it was not tested in the project,\n",
        "# so torch.bfloat16 is used by default.\n",
        "amp_dtype = (\n",
        "    torch.bfloat16\n",
        "    if torch.cuda.is_available() and torch.cuda.is_bf16_supported()\n",
        "    else torch.float16\n",
        "    if torch.cuda.is_available()\n",
        "    else None\n",
        ")\n",
        "# Changing False to True can speed up training\n",
        "# of large enough models on compatible hardware.\n",
        "amp_enabled = False and amp_dtype is not None\n",
        "grad_scaler = torch.cuda.amp.GradScaler() if amp_dtype is torch.float16 else None  # type: ignore\n",
        "\n",
        "# torch.compile\n",
        "compile_model = False\n",
        "\n",
        "# fmt: off\n",
        "print(f'Device:        {device.type.upper()}')\n",
        "print(f'AMP:           {amp_enabled}{f\" ({amp_dtype})\"if amp_enabled else \"\"}')\n",
        "print(f'torch.compile: {compile_model}')\n",
        "# fmt: on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IQmaR2pvh7_"
      },
      "source": [
        "# Model and optimizer\n",
        "\n",
        "The best performance is usually achieved with `num_embeddings`\n",
        "from the `rtdl_num_embeddings` package. Typically, `PiecewiseLinearEmbeddings`\n",
        "and `PeriodicEmbeddings` perform best."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_num_features=train_x.shape[1]\n",
        "# No embeddings.\n",
        "num_embeddings = None"
      ],
      "metadata": {
        "id": "ftEcO4flw-iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Simple embeddings. classification\n",
        "num_embeddings = rtdl_num_embeddings.LinearReLUEmbeddings(n_num_features)\n",
        "\n",
        "# Periodic embeddings.\n",
        "#num_embeddings = rtdl_num_embeddings.PeriodicEmbeddings(n_num_features, lite=False)\n",
        "\n",
        "# Piecewise-linear embeddings. regression\n",
        "#num_embeddings = rtdl_num_embeddings.PiecewiseLinearEmbeddings(\n",
        "#    rtdl_num_embeddings.compute_bins(data['train']['x_num'], n_bins=48),\n",
        "#    d_embedding=16,\n",
        "#    activation=False,\n",
        "#    version='B',\n",
        "#)"
      ],
      "metadata": {
        "id": "wNH0-RiAw_4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlelSNsBvh7_"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "model = tabm.TabM.make(\n",
        "    n_num_features=n_num_features,\n",
        "    cat_cardinalities=cat_cardinalities,\n",
        "    d_out=1 if n_classes is None else n_classes,\n",
        "    num_embeddings=num_embeddings,\n",
        ").to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-3, weight_decay=3e-4)\n",
        "gradient_clipping_norm: Optional[float] = 1.0\n",
        "\n",
        "if compile_model:\n",
        "    # NOTE\n",
        "    # `torch.compile(model, mode=\"reduce-overhead\")` caused issues during training,\n",
        "    # so the `mode` argument is not used.\n",
        "    model = torch.compile(model)\n",
        "    evaluation_mode = torch.no_grad\n",
        "else:\n",
        "    evaluation_mode = torch.inference_mode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "print(f'Total parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
        "\n",
        "\n",
        "#'k': 32,\n",
        "\n",
        "#mnist sin preprocess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMXmCC4Oc80x",
        "outputId": "fd639ac2-9105-4c5b-f0f5-0b3cd8b55d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TabM(\n",
            "  (ensemble_view): EnsembleView()\n",
            "  (backbone): MLPBackboneBatchEnsemble(\n",
            "    (blocks): ModuleList(\n",
            "      (0-2): 3 x Sequential(\n",
            "        (0): LinearBatchEnsemble()\n",
            "        (1): ReLU()\n",
            "        (2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (output): LinearEnsemble()\n",
            ")\n",
            "Total parameters: 1,246,016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "print(f'Total parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}')\n",
        "\n",
        "\n",
        "#'k': 32,\n",
        "\n",
        "#mnist con preprocess"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KueYhHcp1ryj",
        "outputId": "ec23f104-8cb5-4228-c9d4-bd868ad048f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TabM(\n",
            "  (num_module): LinearReLUEmbeddings(\n",
            "    (linear): LinearEmbeddings()\n",
            "    (activation): ReLU()\n",
            "  )\n",
            "  (ensemble_view): EnsembleView()\n",
            "  (backbone): MLPBackboneBatchEnsemble(\n",
            "    (blocks): ModuleList(\n",
            "      (0-1): 2 x Sequential(\n",
            "        (0): LinearBatchEnsemble()\n",
            "        (1): ReLU()\n",
            "        (2): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (output): LinearEnsemble()\n",
            ")\n",
            "Total parameters: 14,206,272\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TADpf0W5vh7_"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wvt5SxsFvh7_"
      },
      "outputs": [],
      "source": [
        "# A quick reminder: TabM represents an ensemble of k MLPs.\n",
        "#\n",
        "# The option below determines if the MLPs are trained\n",
        "# on the same batches (share_training_batches=True) or\n",
        "# on different batches. Technically, this option determines:\n",
        "# - How the loss function is implemented.\n",
        "# - How the training batches are constructed.\n",
        "#\n",
        "# `True` is recommended by default because of better training efficiency.\n",
        "# On some tasks, `False` may provide better performance.\n",
        "share_training_batches = True\n",
        "task_is_regression = task_type == 'regression'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-poNZF_vh8A",
        "outputId": "42c89e3f-ba36-4d1b-af1c-177de394125c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test score before training: 0.0044\n"
          ]
        }
      ],
      "source": [
        "@torch.autocast(device.type, enabled=amp_enabled, dtype=amp_dtype)  # type: ignore[code]\n",
        "def apply_model(part: str, idx: Tensor) -> Tensor:\n",
        "    return (\n",
        "        model(\n",
        "            data[part]['x_num'][idx],\n",
        "            data[part]['x_cat'][idx] if 'x_cat' in data[part] else None,\n",
        "        )\n",
        "        .squeeze(-1)  # Remove the last dimension for regression tasks.\n",
        "        .float()\n",
        "    )\n",
        "\n",
        "\n",
        "base_loss_fn = (\n",
        "    nn.functional.mse_loss if task_is_regression else nn.functional.cross_entropy\n",
        ")\n",
        "\n",
        "\n",
        "def loss_fn(y_pred: Tensor, y_true: Tensor) -> Tensor:\n",
        "    # TabM produces k predictions. Each of them must be trained separately.\n",
        "\n",
        "    # Regression:     (batch_size, k)            -> (batch_size * k,)\n",
        "    # Classification: (batch_size, k, n_classes) -> (batch_size * k, n_classes)\n",
        "    y_pred = y_pred.flatten(0, 1)\n",
        "\n",
        "    if share_training_batches:\n",
        "        # (batch_size,) -> (batch_size * k,)\n",
        "        y_true = y_true.repeat_interleave(model.backbone.k)\n",
        "    else:\n",
        "        # (batch_size, k) -> (batch_size * k,)\n",
        "        y_true = y_true.flatten(0, 1)\n",
        "\n",
        "    return base_loss_fn(y_pred, y_true)\n",
        "\n",
        "@evaluation_mode()\n",
        "def evaluate(part: str) -> float:\n",
        "    model.eval()\n",
        "\n",
        "    # When using torch.compile, you may need to reduce the evaluation batch size.\n",
        "    eval_batch_size = 8096\n",
        "    y_pred: np.ndarray = (\n",
        "        torch.cat(\n",
        "            [\n",
        "                apply_model(part, idx)\n",
        "                for idx in torch.arange(len(data[part]['y']), device=device).split(eval_batch_size)\n",
        "            ]\n",
        "        )\n",
        "        .cpu()\n",
        "        .numpy()\n",
        "    )\n",
        "    if task_type == 'regression':\n",
        "        # Transform the predictions back to the original label space.\n",
        "        if regression_label_stats is not None:\n",
        "          y_pred = y_pred * regression_label_stats.std + regression_label_stats.mean\n",
        "\n",
        "    # Compute the mean of the k predictions.\n",
        "    if not task_is_regression:\n",
        "        # For classification, the mean must be computed in the probability space.\n",
        "        y_pred = scipy.special.softmax(y_pred, axis=-1)\n",
        "    y_pred = y_pred.mean(1)\n",
        "\n",
        "    y_true = data[part]['y'].cpu().numpy()\n",
        "    #if part==\"test\":\n",
        "      #print(\"test: \", y_true[:10])\n",
        "      #print(\"pred: \", y_pred[:10])\n",
        "    #print(\"mean y_pred_test: \", y_pred)\n",
        "    #print(y_true)\n",
        "    y_pred=np.argmax(y_pred,axis=1)\n",
        "    #print(y_pred)\n",
        "    score = (\n",
        "        -(sklearn.metrics.mean_squared_error(y_true, y_pred)**0.5 )\n",
        "        if task_type == 'regression'\n",
        "        else  f1_score(y_true, y_pred, average=\"weighted\")\n",
        "        #sklearn.metrics.accuracy_score(y_true, y_pred.argmax(1))\n",
        "        )\n",
        "    return float(score)  # The higher -- the better.\n",
        "\n",
        "\n",
        "print(f'Test score before training: {evaluate(\"test\"):.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41QacO7Cvh8A",
        "outputId": "8e5f15cc-b450-477b-f5d2-6238e60d8856",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* [epoch] 0   [val] 0.186 [test] 0.163\n",
            "* [epoch] 1   [val] 0.511 [test] 0.493\n",
            "* [epoch] 2   [val] 0.597 [test] 0.601\n",
            "* [epoch] 3   [val] 0.687 [test] 0.718\n",
            "* [epoch] 4   [val] 0.798 [test] 0.859\n",
            "* [epoch] 5   [val] 0.827 [test] 0.892\n",
            "* [epoch] 6   [val] 0.877 [test] 0.886\n",
            "  [epoch] 7   [val] 0.871 [test] 0.893\n",
            "* [epoch] 8   [val] 0.935 [test] 0.919\n",
            "  [epoch] 9   [val] 0.913 [test] 0.927\n",
            "  [epoch] 10  [val] 0.931 [test] 0.930\n",
            "  [epoch] 11  [val] 0.912 [test] 0.936\n",
            "* [epoch] 12  [val] 0.936 [test] 0.929\n",
            "* [epoch] 13  [val] 0.950 [test] 0.934\n",
            "  [epoch] 14  [val] 0.945 [test] 0.938\n",
            "* [epoch] 15  [val] 0.964 [test] 0.942\n",
            "  [epoch] 16  [val] 0.945 [test] 0.949\n",
            "  [epoch] 17  [val] 0.950 [test] 0.940\n",
            "  [epoch] 18  [val] 0.932 [test] 0.938\n",
            "  [epoch] 19  [val] 0.960 [test] 0.940\n",
            "  [epoch] 20  [val] 0.955 [test] 0.945\n",
            "  [epoch] 21  [val] 0.950 [test] 0.945\n",
            "  [epoch] 22  [val] 0.954 [test] 0.941\n",
            "  [epoch] 23  [val] 0.959 [test] 0.943\n",
            "  [epoch] 24  [val] 0.950 [test] 0.945\n",
            "  [epoch] 25  [val] 0.959 [test] 0.940\n",
            "  [epoch] 26  [val] 0.950 [test] 0.945\n",
            "  [epoch] 27  [val] 0.950 [test] 0.949\n",
            "  [epoch] 28  [val] 0.954 [test] 0.945\n",
            "  [epoch] 29  [val] 0.950 [test] 0.945\n",
            "  [epoch] 30  [val] 0.950 [test] 0.943\n",
            "  [epoch] 31  [val] 0.955 [test] 0.940\n",
            "  [epoch] 32  [val] 0.954 [test] 0.945\n",
            "\n",
            "[Summary]\n",
            "best epoch:  15\n",
            "val score:  0.9638849844060695\n",
            "test score: 0.9424442011988456\n",
            "* [epoch] 0   [val] 0.941 [test] 0.945\n",
            "* [epoch] 1   [val] 0.946 [test] 0.934\n",
            "  [epoch] 2   [val] 0.935 [test] 0.936\n",
            "  [epoch] 3   [val] 0.946 [test] 0.938\n",
            "  [epoch] 4   [val] 0.945 [test] 0.932\n",
            "* [epoch] 5   [val] 0.955 [test] 0.940\n",
            "* [epoch] 6   [val] 0.959 [test] 0.938\n",
            "  [epoch] 7   [val] 0.946 [test] 0.938\n",
            "  [epoch] 8   [val] 0.955 [test] 0.943\n",
            "  [epoch] 9   [val] 0.959 [test] 0.938\n",
            "  [epoch] 10  [val] 0.950 [test] 0.943\n",
            "  [epoch] 11  [val] 0.955 [test] 0.940\n",
            "  [epoch] 12  [val] 0.950 [test] 0.942\n",
            "  [epoch] 13  [val] 0.954 [test] 0.943\n",
            "  [epoch] 14  [val] 0.954 [test] 0.943\n",
            "  [epoch] 15  [val] 0.950 [test] 0.940\n",
            "  [epoch] 16  [val] 0.959 [test] 0.942\n",
            "  [epoch] 17  [val] 0.954 [test] 0.945\n",
            "  [epoch] 18  [val] 0.950 [test] 0.942\n",
            "  [epoch] 19  [val] 0.950 [test] 0.947\n",
            "  [epoch] 20  [val] 0.959 [test] 0.945\n",
            "  [epoch] 21  [val] 0.950 [test] 0.947\n",
            "  [epoch] 22  [val] 0.950 [test] 0.942\n",
            "  [epoch] 23  [val] 0.955 [test] 0.945\n",
            "\n",
            "[Summary]\n",
            "best epoch:  6\n",
            "val score:  0.9592501319871719\n",
            "test score: 0.938261508319409\n",
            "* [epoch] 0   [val] 0.955 [test] 0.940\n",
            "* [epoch] 1   [val] 0.959 [test] 0.945\n",
            "  [epoch] 2   [val] 0.959 [test] 0.942\n",
            "  [epoch] 3   [val] 0.959 [test] 0.943\n",
            "  [epoch] 4   [val] 0.954 [test] 0.940\n",
            "  [epoch] 5   [val] 0.950 [test] 0.943\n",
            "  [epoch] 6   [val] 0.955 [test] 0.943\n",
            "* [epoch] 7   [val] 0.964 [test] 0.945\n",
            "  [epoch] 8   [val] 0.954 [test] 0.940\n",
            "  [epoch] 9   [val] 0.954 [test] 0.945\n",
            "  [epoch] 10  [val] 0.950 [test] 0.940\n",
            "  [epoch] 11  [val] 0.950 [test] 0.945\n",
            "  [epoch] 12  [val] 0.950 [test] 0.947\n",
            "  [epoch] 13  [val] 0.950 [test] 0.947\n",
            "  [epoch] 14  [val] 0.955 [test] 0.940\n",
            "  [epoch] 15  [val] 0.954 [test] 0.947\n",
            "  [epoch] 16  [val] 0.950 [test] 0.945\n",
            "  [epoch] 17  [val] 0.954 [test] 0.947\n",
            "  [epoch] 18  [val] 0.950 [test] 0.945\n",
            "  [epoch] 19  [val] 0.950 [test] 0.943\n",
            "  [epoch] 20  [val] 0.954 [test] 0.943\n",
            "  [epoch] 21  [val] 0.954 [test] 0.947\n",
            "  [epoch] 22  [val] 0.954 [test] 0.949\n",
            "  [epoch] 23  [val] 0.954 [test] 0.947\n",
            "  [epoch] 24  [val] 0.959 [test] 0.951\n",
            "\n",
            "[Summary]\n",
            "best epoch:  7\n",
            "val score:  0.9638304789060405\n",
            "test score: 0.9446674133420483\n",
            "* [epoch] 0   [val] 0.955 [test] 0.943\n",
            "  [epoch] 1   [val] 0.954 [test] 0.943\n",
            "  [epoch] 2   [val] 0.954 [test] 0.943\n",
            "  [epoch] 3   [val] 0.950 [test] 0.943\n",
            "  [epoch] 4   [val] 0.950 [test] 0.949\n",
            "  [epoch] 5   [val] 0.950 [test] 0.943\n",
            "  [epoch] 6   [val] 0.954 [test] 0.945\n",
            "* [epoch] 7   [val] 0.959 [test] 0.945\n",
            "  [epoch] 8   [val] 0.959 [test] 0.943\n",
            "  [epoch] 9   [val] 0.954 [test] 0.953\n",
            "* [epoch] 10  [val] 0.959 [test] 0.947\n",
            "  [epoch] 11  [val] 0.955 [test] 0.947\n",
            "* [epoch] 12  [val] 0.964 [test] 0.947\n",
            "  [epoch] 13  [val] 0.950 [test] 0.949\n",
            "  [epoch] 14  [val] 0.955 [test] 0.949\n",
            "  [epoch] 15  [val] 0.959 [test] 0.945\n",
            "  [epoch] 16  [val] 0.959 [test] 0.949\n",
            "  [epoch] 17  [val] 0.950 [test] 0.947\n",
            "  [epoch] 18  [val] 0.955 [test] 0.947\n",
            "  [epoch] 19  [val] 0.964 [test] 0.947\n",
            "  [epoch] 20  [val] 0.959 [test] 0.947\n",
            "  [epoch] 21  [val] 0.954 [test] 0.949\n",
            "  [epoch] 22  [val] 0.959 [test] 0.945\n",
            "  [epoch] 23  [val] 0.959 [test] 0.947\n",
            "  [epoch] 24  [val] 0.954 [test] 0.947\n",
            "  [epoch] 25  [val] 0.959 [test] 0.949\n",
            "  [epoch] 26  [val] 0.959 [test] 0.951\n",
            "  [epoch] 27  [val] 0.954 [test] 0.945\n",
            "  [epoch] 28  [val] 0.964 [test] 0.947\n",
            "  [epoch] 29  [val] 0.950 [test] 0.945\n",
            "\n",
            "[Summary]\n",
            "best epoch:  12\n",
            "val score:  0.9635635061974883\n",
            "test score: 0.9468531093605744\n",
            "* [epoch] 0   [val] 0.954 [test] 0.949\n",
            "* [epoch] 1   [val] 0.955 [test] 0.945\n",
            "  [epoch] 2   [val] 0.955 [test] 0.947\n",
            "  [epoch] 3   [val] 0.954 [test] 0.951\n",
            "  [epoch] 4   [val] 0.950 [test] 0.945\n",
            "  [epoch] 5   [val] 0.954 [test] 0.943\n",
            "* [epoch] 6   [val] 0.963 [test] 0.945\n",
            "  [epoch] 7   [val] 0.954 [test] 0.943\n",
            "  [epoch] 8   [val] 0.950 [test] 0.945\n",
            "  [epoch] 9   [val] 0.954 [test] 0.949\n",
            "  [epoch] 10  [val] 0.959 [test] 0.945\n",
            "  [epoch] 11  [val] 0.950 [test] 0.947\n",
            "  [epoch] 12  [val] 0.954 [test] 0.945\n",
            "  [epoch] 13  [val] 0.959 [test] 0.947\n",
            "  [epoch] 14  [val] 0.954 [test] 0.949\n",
            "  [epoch] 15  [val] 0.955 [test] 0.949\n",
            "  [epoch] 16  [val] 0.955 [test] 0.947\n",
            "* [epoch] 17  [val] 0.964 [test] 0.943\n",
            "  [epoch] 18  [val] 0.950 [test] 0.945\n",
            "  [epoch] 19  [val] 0.964 [test] 0.945\n",
            "  [epoch] 20  [val] 0.959 [test] 0.945\n",
            "* [epoch] 21  [val] 0.964 [test] 0.947\n",
            "  [epoch] 22  [val] 0.959 [test] 0.953\n",
            "  [epoch] 23  [val] 0.959 [test] 0.947\n",
            "  [epoch] 24  [val] 0.964 [test] 0.949\n",
            "  [epoch] 25  [val] 0.959 [test] 0.943\n",
            "  [epoch] 26  [val] 0.959 [test] 0.945\n",
            "  [epoch] 27  [val] 0.959 [test] 0.949\n",
            "  [epoch] 28  [val] 0.954 [test] 0.947\n",
            "  [epoch] 29  [val] 0.959 [test] 0.945\n",
            "  [epoch] 30  [val] 0.959 [test] 0.951\n",
            "  [epoch] 31  [val] 0.959 [test] 0.947\n",
            "  [epoch] 32  [val] 0.959 [test] 0.947\n",
            "  [epoch] 33  [val] 0.959 [test] 0.947\n",
            "  [epoch] 34  [val] 0.959 [test] 0.945\n",
            "  [epoch] 35  [val] 0.954 [test] 0.945\n",
            "  [epoch] 36  [val] 0.959 [test] 0.949\n",
            "  [epoch] 37  [val] 0.959 [test] 0.951\n",
            "  [epoch] 38  [val] 0.954 [test] 0.947\n",
            "\n",
            "[Summary]\n",
            "best epoch:  21\n",
            "val score:  0.9635672760303434\n",
            "test score: 0.9468039128334452\n",
            "* [epoch] 0   [val] 0.954 [test] 0.951\n",
            "* [epoch] 1   [val] 0.959 [test] 0.949\n",
            "  [epoch] 2   [val] 0.959 [test] 0.943\n",
            "  [epoch] 3   [val] 0.959 [test] 0.953\n",
            "  [epoch] 4   [val] 0.959 [test] 0.947\n",
            "  [epoch] 5   [val] 0.954 [test] 0.945\n",
            "  [epoch] 6   [val] 0.954 [test] 0.945\n",
            "  [epoch] 7   [val] 0.959 [test] 0.945\n",
            "* [epoch] 8   [val] 0.959 [test] 0.945\n",
            "  [epoch] 9   [val] 0.954 [test] 0.947\n",
            "  [epoch] 10  [val] 0.959 [test] 0.943\n",
            "  [epoch] 11  [val] 0.954 [test] 0.940\n",
            "  [epoch] 12  [val] 0.959 [test] 0.943\n",
            "  [epoch] 13  [val] 0.954 [test] 0.947\n",
            "  [epoch] 14  [val] 0.954 [test] 0.945\n",
            "* [epoch] 15  [val] 0.963 [test] 0.943\n",
            "  [epoch] 16  [val] 0.959 [test] 0.947\n",
            "  [epoch] 17  [val] 0.959 [test] 0.945\n",
            "  [epoch] 18  [val] 0.954 [test] 0.947\n",
            "  [epoch] 19  [val] 0.959 [test] 0.949\n",
            "  [epoch] 20  [val] 0.959 [test] 0.953\n",
            "* [epoch] 21  [val] 0.968 [test] 0.949\n",
            "  [epoch] 22  [val] 0.964 [test] 0.947\n",
            "  [epoch] 23  [val] 0.964 [test] 0.945\n",
            "  [epoch] 24  [val] 0.954 [test] 0.949\n",
            "  [epoch] 25  [val] 0.959 [test] 0.945\n",
            "  [epoch] 26  [val] 0.959 [test] 0.947\n",
            "  [epoch] 27  [val] 0.964 [test] 0.943\n",
            "  [epoch] 28  [val] 0.959 [test] 0.945\n",
            "  [epoch] 29  [val] 0.964 [test] 0.945\n",
            "  [epoch] 30  [val] 0.964 [test] 0.947\n",
            "  [epoch] 31  [val] 0.964 [test] 0.945\n",
            "  [epoch] 32  [val] 0.959 [test] 0.947\n",
            "  [epoch] 33  [val] 0.959 [test] 0.951\n",
            "  [epoch] 34  [val] 0.964 [test] 0.947\n",
            "  [epoch] 35  [val] 0.954 [test] 0.951\n",
            "  [epoch] 36  [val] 0.959 [test] 0.947\n",
            "  [epoch] 37  [val] 0.959 [test] 0.949\n",
            "  [epoch] 38  [val] 0.959 [test] 0.947\n",
            "\n",
            "[Summary]\n",
            "best epoch:  21\n",
            "val score:  0.9681476229492119\n",
            "test score: 0.9489599752034543\n",
            "* [epoch] 0   [val] 0.964 [test] 0.949\n",
            "  [epoch] 1   [val] 0.959 [test] 0.949\n",
            "  [epoch] 2   [val] 0.959 [test] 0.945\n",
            "  [epoch] 3   [val] 0.964 [test] 0.945\n",
            "  [epoch] 4   [val] 0.964 [test] 0.945\n",
            "  [epoch] 5   [val] 0.954 [test] 0.947\n",
            "  [epoch] 6   [val] 0.959 [test] 0.949\n",
            "  [epoch] 7   [val] 0.959 [test] 0.947\n",
            "  [epoch] 8   [val] 0.959 [test] 0.947\n",
            "  [epoch] 9   [val] 0.959 [test] 0.945\n",
            "  [epoch] 10  [val] 0.964 [test] 0.947\n",
            "* [epoch] 11  [val] 0.968 [test] 0.945\n",
            "  [epoch] 12  [val] 0.964 [test] 0.949\n",
            "  [epoch] 13  [val] 0.964 [test] 0.943\n",
            "  [epoch] 14  [val] 0.964 [test] 0.949\n",
            "  [epoch] 15  [val] 0.964 [test] 0.947\n",
            "  [epoch] 16  [val] 0.964 [test] 0.947\n",
            "  [epoch] 17  [val] 0.964 [test] 0.947\n",
            "  [epoch] 18  [val] 0.964 [test] 0.949\n",
            "  [epoch] 19  [val] 0.964 [test] 0.949\n",
            "  [epoch] 20  [val] 0.964 [test] 0.949\n",
            "  [epoch] 21  [val] 0.959 [test] 0.951\n",
            "  [epoch] 22  [val] 0.959 [test] 0.945\n",
            "  [epoch] 23  [val] 0.959 [test] 0.947\n",
            "  [epoch] 24  [val] 0.959 [test] 0.949\n",
            "  [epoch] 25  [val] 0.964 [test] 0.943\n",
            "  [epoch] 26  [val] 0.959 [test] 0.949\n",
            "  [epoch] 27  [val] 0.964 [test] 0.947\n",
            "  [epoch] 28  [val] 0.964 [test] 0.945\n",
            "\n",
            "[Summary]\n",
            "best epoch:  11\n",
            "val score:  0.9681476229492119\n",
            "test score: 0.9447319754302197\n",
            "* [epoch] 0   [val] 0.964 [test] 0.949\n",
            "  [epoch] 1   [val] 0.959 [test] 0.947\n",
            "  [epoch] 2   [val] 0.964 [test] 0.945\n",
            "  [epoch] 3   [val] 0.964 [test] 0.947\n",
            "  [epoch] 4   [val] 0.959 [test] 0.949\n",
            "  [epoch] 5   [val] 0.964 [test] 0.947\n",
            "  [epoch] 6   [val] 0.959 [test] 0.949\n",
            "  [epoch] 7   [val] 0.964 [test] 0.949\n",
            "* [epoch] 8   [val] 0.968 [test] 0.949\n",
            "  [epoch] 9   [val] 0.964 [test] 0.956\n",
            "  [epoch] 10  [val] 0.964 [test] 0.949\n",
            "  [epoch] 11  [val] 0.964 [test] 0.949\n",
            "  [epoch] 12  [val] 0.959 [test] 0.949\n",
            "  [epoch] 13  [val] 0.959 [test] 0.947\n",
            "  [epoch] 14  [val] 0.968 [test] 0.947\n",
            "  [epoch] 15  [val] 0.964 [test] 0.947\n",
            "  [epoch] 16  [val] 0.959 [test] 0.945\n",
            "  [epoch] 17  [val] 0.964 [test] 0.949\n",
            "  [epoch] 18  [val] 0.964 [test] 0.949\n",
            "  [epoch] 19  [val] 0.959 [test] 0.949\n",
            "  [epoch] 20  [val] 0.964 [test] 0.945\n",
            "  [epoch] 21  [val] 0.959 [test] 0.949\n",
            "  [epoch] 22  [val] 0.964 [test] 0.947\n",
            "  [epoch] 23  [val] 0.959 [test] 0.945\n",
            "  [epoch] 24  [val] 0.954 [test] 0.947\n",
            "  [epoch] 25  [val] 0.968 [test] 0.947\n",
            "\n",
            "[Summary]\n",
            "best epoch:  8\n",
            "val score:  0.9681476229492119\n",
            "test score: 0.9490089047207664\n",
            "* [epoch] 0   [val] 0.964 [test] 0.951\n",
            "  [epoch] 1   [val] 0.964 [test] 0.947\n",
            "  [epoch] 2   [val] 0.959 [test] 0.949\n",
            "  [epoch] 3   [val] 0.954 [test] 0.947\n",
            "  [epoch] 4   [val] 0.959 [test] 0.945\n",
            "  [epoch] 5   [val] 0.959 [test] 0.943\n",
            "  [epoch] 6   [val] 0.959 [test] 0.947\n",
            "  [epoch] 7   [val] 0.959 [test] 0.947\n",
            "  [epoch] 8   [val] 0.964 [test] 0.947\n",
            "  [epoch] 9   [val] 0.964 [test] 0.943\n",
            "  [epoch] 10  [val] 0.964 [test] 0.945\n",
            "  [epoch] 11  [val] 0.964 [test] 0.947\n",
            "  [epoch] 12  [val] 0.964 [test] 0.949\n",
            "  [epoch] 13  [val] 0.964 [test] 0.945\n",
            "  [epoch] 14  [val] 0.964 [test] 0.949\n",
            "  [epoch] 15  [val] 0.964 [test] 0.947\n",
            "  [epoch] 16  [val] 0.959 [test] 0.949\n",
            "  [epoch] 17  [val] 0.964 [test] 0.951\n",
            "\n",
            "[Summary]\n",
            "best epoch:  0\n",
            "val score:  0.9635260649029963\n",
            "test score: 0.9512480391630047\n",
            "* [epoch] 0   [val] 0.964 [test] 0.947\n",
            "  [epoch] 1   [val] 0.964 [test] 0.951\n",
            "  [epoch] 2   [val] 0.959 [test] 0.947\n",
            "  [epoch] 3   [val] 0.964 [test] 0.949\n",
            "  [epoch] 4   [val] 0.964 [test] 0.947\n",
            "  [epoch] 5   [val] 0.959 [test] 0.945\n",
            "  [epoch] 6   [val] 0.954 [test] 0.949\n",
            "  [epoch] 7   [val] 0.964 [test] 0.945\n",
            "  [epoch] 8   [val] 0.959 [test] 0.949\n",
            "  [epoch] 9   [val] 0.950 [test] 0.947\n",
            "  [epoch] 10  [val] 0.959 [test] 0.947\n",
            "  [epoch] 11  [val] 0.959 [test] 0.945\n",
            "  [epoch] 12  [val] 0.959 [test] 0.949\n",
            "  [epoch] 13  [val] 0.959 [test] 0.947\n",
            "  [epoch] 14  [val] 0.959 [test] 0.943\n",
            "  [epoch] 15  [val] 0.959 [test] 0.945\n",
            "  [epoch] 16  [val] 0.959 [test] 0.951\n",
            "  [epoch] 17  [val] 0.964 [test] 0.949\n",
            "\n",
            "[Summary]\n",
            "best epoch:  0\n",
            "val score:  0.9635260649029963\n",
            "test score: 0.9468344317926901\n"
          ]
        }
      ],
      "source": [
        "l_mlp=[]\n",
        "for _ in range(10):\n",
        "  n_epochs = 100\n",
        "  train_size = train_x.shape[0]\n",
        "  batch_size = 128 # Reduced batch size\n",
        "  epoch_size = math.ceil(train_size / batch_size)\n",
        "\n",
        "  epoch = -1\n",
        "  metrics = {'val': -math.inf, 'test': -math.inf}\n",
        "\n",
        "\n",
        "  def make_checkpoint() -> dict[str, Any]:\n",
        "      return deepcopy(\n",
        "          {\n",
        "              'model': model.state_dict(),\n",
        "              'optimizer': optimizer.state_dict(),\n",
        "              'epoch': epoch,\n",
        "              'metrics': metrics,\n",
        "          }\n",
        "      )\n",
        "\n",
        "\n",
        "  best_checkpoint = make_checkpoint()\n",
        "\n",
        "  # Early stopping: the training stops if the validation score\n",
        "  # does not improve for more than `patience` consecutive epochs.\n",
        "  patience = 16\n",
        "  remaining_patience = patience\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "      batches = (\n",
        "          # Create one standard batch sequence.\n",
        "          torch.randperm(train_size, device=device).split(batch_size)\n",
        "          if share_training_batches\n",
        "          # Create k independent batch sequences.\n",
        "          else (\n",
        "              torch.rand((train_size, model.backbone.k), device=device)\n",
        "              .argsort(dim=0)\n",
        "              .split(batch_size, dim=0)\n",
        "          )\n",
        "      )\n",
        "      for batch_idx in batches:\n",
        "          model.train()\n",
        "          optimizer.zero_grad()\n",
        "          loss = loss_fn(apply_model('train', batch_idx), Y_train[batch_idx])\n",
        "          if gradient_clipping_norm is not None:\n",
        "              if grad_scaler is not None:\n",
        "                  grad_scaler.unscale_(optimizer)\n",
        "              torch.nn.utils.clip_grad.clip_grad_norm_(\n",
        "                  model.parameters(), gradient_clipping_norm\n",
        "              )\n",
        "          if grad_scaler is None:\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "          else:\n",
        "              grad_scaler.scale(loss).backward()  # type: ignore\n",
        "              grad_scaler.step(optimizer)\n",
        "              grad_scaler.update()\n",
        "\n",
        "      metrics = {part: evaluate(part) for part in ['val', 'test']}\n",
        "      val_score_improved = metrics['val'] > best_checkpoint['metrics']['val']\n",
        "\n",
        "      print(\n",
        "          f'{\"*\" if val_score_improved else \" \"}'\n",
        "          f' [epoch] {epoch:<3}'\n",
        "          f' [val] {metrics[\"val\"]:.3f}'\n",
        "          f' [test] {metrics[\"test\"]:.3f}'\n",
        "      )\n",
        "\n",
        "      if val_score_improved:\n",
        "          best_checkpoint = make_checkpoint()\n",
        "          remaining_patience = patience\n",
        "      else:\n",
        "          remaining_patience -= 1\n",
        "\n",
        "      if remaining_patience < 0:\n",
        "          break\n",
        "\n",
        "  # To make final predictions, load the best checkpoint.\n",
        "  model.load_state_dict(best_checkpoint['model'])\n",
        "\n",
        "  print('\\n[Summary]')\n",
        "  print(f'best epoch:  {best_checkpoint[\"epoch\"]}')\n",
        "  print(f'val score:  {best_checkpoint[\"metrics\"][\"val\"]}')\n",
        "  print(f'test score: {best_checkpoint[\"metrics\"][\"test\"]}')\n",
        "  l_mlp.append(-best_checkpoint[\"metrics\"][\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import re\n",
        "\n",
        "def get_gpu_info():\n",
        "    try:\n",
        "        result = subprocess.check_output(\n",
        "            ['nvidia-smi', '--query-gpu=name,memory.total,driver_version,compute_cap', '--format=csv,noheader,nounits'],\n",
        "            encoding='utf-8'\n",
        "        )\n",
        "        gpus = result.strip().split('\\n')\n",
        "        for i, gpu in enumerate(gpus):\n",
        "            name, memory, driver, compute = [x.strip() for x in gpu.split(',')]\n",
        "            print(f\"GPU {i}:\")\n",
        "            print(f\"  Model: {name}\")\n",
        "            print(f\"  Memory: {memory} MB\")\n",
        "            print(f\"  Driver Version: {driver}\")\n",
        "            print(f\"  Compute Capability: {compute}\")\n",
        "            print()\n",
        "    except FileNotFoundError:\n",
        "        print(\"nvidia-smi no está disponible. ¿Tienes drivers NVIDIA instalados?\")\n",
        "    except Exception as e:\n",
        "        print(\"Error obteniendo información de la GPU:\", e)\n",
        "\n",
        "get_gpu_info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS58UNPOGl24",
        "outputId": "b74f4cea-e6ce-4174-8950-930b92396381"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0:\n",
            "  Model: Tesla T4\n",
            "  Memory: 15360 MB\n",
            "  Driver Version: 550.54.15\n",
            "  Compute Capability: 7.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST: TabM fair comparison: 24 min\n",
        "\n",
        "mnist con preprocessing  CUDA out of memory. Tried to allocate 24.21 GiB"
      ],
      "metadata": {
        "id": "ZOut1PggA09f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#housing embeddings and preprocessing\n",
        "print(\"TabM: \", np.round(np.min(l_mlp),5), np.round(np.mean(l_mlp),4), \" +- \", np.round(np.std(l_mlp),4) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMdQ1DcYwKaH",
        "outputId": "b34836f7-b197-489a-e50c-2194e6343b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TabM:  0.06595 0.0705  +-  0.0049\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#housing fair comparison\n",
        "print(\"TabM: \", np.round(np.min(l_mlp),5), np.round(np.mean(l_mlp),4), \" +- \", np.round(np.std(l_mlp),4) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDj3HWHJf-b8",
        "outputId": "14281e92-ff09-4d24-898f-a6904c0c8f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TabM:  0.09182 0.0953  +-  0.0022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#abalone fair comparison\n",
        "print(\"TabM: \", np.round(np.min(l_mlp),5), np.round(np.mean(l_mlp),4), \" +- \", np.round(np.std(l_mlp),4) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWz2vJEuxYSI",
        "outputId": "3bd86859-935b-4cfa-a959-ba462e4b27fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TabM:  0.06784 0.0686  +-  0.0007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#abalone embeddings and preprocessing\n",
        "print(\"TabM: \", np.round(np.min(l_mlp),5), np.round(np.mean(l_mlp),4), \" +- \", np.round(np.std(l_mlp),4) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fgo1uwo11QEH",
        "outputId": "f845914b-5b9a-402b-ba65-000e57f6e76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TabM:  0.06887 0.0694  +-  0.0003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#izmir fair comparison\n",
        "print(\"TabM: \", np.round(np.min(l_mlp),5), np.round(np.mean(l_mlp),4), \" +- \", np.round(np.std(l_mlp),4) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k_g0L1Lypf0",
        "outputId": "d90dba63-623c-4fa0-d977-11fea26ff844"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TabM:  0.01838 0.0187  +-  0.0002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#izmir embeddings and preprocessing\n",
        "print(\"TabM: \", np.round(np.min(l_mlp),5), np.round(np.mean(l_mlp),4), \" +- \", np.round(np.std(l_mlp),4) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LqAPvMG5nZD",
        "outputId": "3073eade-d8e0-465f-c04f-4a3320255353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TabM:  0.01853 0.0192  +-  0.0006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MNISTfair comparison\n",
        "print(np.round(100* np.mean(l_mlp),2), \" +- \", np.round(100*np.std(l_mlp),2))\n",
        "# with embeddings requieres more than 24 gb of VRAM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxvtCQC659Qz",
        "outputId": "0b9c0ffd-31d9-4fe0-ef3c-942d1c39a9a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-98.45  +-  0.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#coil 100 fair comparison\n",
        "print(np.round(100* np.mean(l_mlp),2), \" +- \", np.round(100*np.std(l_mlp),2))\n",
        "# with embeddings requieres more than 24 gb of VRAM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO4Q_DA8ONHA",
        "outputId": "8a34b6bf-b84b-49ac-bb73-4274e5892ebc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-98.81  +-  0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#isolet fair comparison\n",
        "print(np.round(100* np.mean(l_mlp),2), \" +- \", np.round(100*np.std(l_mlp),2))\n",
        "# with embeddings requieres more than 24 gb of VRAM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk749p84PJAJ",
        "outputId": "c6e77ca3-5051-47a1-f654-1a9ddd74fd41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-94.6  +-  0.35\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "A4LRByuSvh79",
        "V33T4jG-0qZf",
        "MzFXgBorTXTJ",
        "x8tJrgi31etV",
        "YUTrk-Up6jpL"
      ],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}